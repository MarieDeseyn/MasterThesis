{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6550cff4",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33524b3c",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465507ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd06aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import lmfit\n",
    "from lmfit.models import Model\n",
    "import numpy as np\n",
    "from uncertainties import ufloat as uf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df56c72",
   "metadata": {},
   "source": [
    "### Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e58d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_fitfunction(x, a0, a1, a2, a3, a4):\n",
    "    return np.exp(a0 + a1*np.log(x) + a2*(np.log(x))**2 + a3*(np.log(x))**3 + a4*(np.log(x))**4)\n",
    "\n",
    "\n",
    "def eff_point(fitresult, E):\n",
    "    return fitresult.eval(x=E)\n",
    "\n",
    "\n",
    "def eff_errpoint(fitresult, mean_sys, lower_sys, upper_sys, x_cont, E):\n",
    "    meanval = np.interp(E, x_cont, mean_sys)\n",
    "    lower = np.interp(E, x_cont, lower_sys) - meanval\n",
    "    upper = np.interp(E, x_cont, upper_sys) - meanval\n",
    "    return [meanval, lower, upper]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb86b0d",
   "metadata": {},
   "source": [
    "### Load the datapoints and uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of samples for the systematic error and the number of points for the linspace\n",
    "N_randoms = 500\n",
    "N_points = 500\n",
    "\n",
    "# import the input for efficiency fits in 2d arrays: dimension 1 = source, dimension 2 = datapoint or error\n",
    "#arr_eff = np.array([[1.31*10**(-4)*28.58/(28.58+0.016)          ,2.53*10**(-4)*7.583/(7.583+0.0046+0.072)                         ,1.52*10**(-4)*26.5/(26.5+0.036+0.0093)                        ,2.83*10**(-5),2.01*10**(-5)*14.605/(14.605+0.135+0.0037)                    ,1.07*10**(-5)],[3.65*10**(-5)]], dtype = 'object')\n",
    "arr_eff = np.array([[1.566*10**(-4)*28.58/(28.58+0.016)          ,2.702*10**(-4)*7.583/(7.583+0.0046+0.072)                         ,1.556*10**(-4)*26.5/(26.5+0.036+0.0093)                        ,4.077*10**(-5),2.902*10**(-5)*14.605/(14.605+0.135+0.0037)                    ,1.174*10**(-5)],[3.864*10**(-5)],[1.938*10**(-4),1.694*10**(-4),1.274*10**(-4),1.07*10**(-4)],[1.761*10**(-5),1.332*10**(-5)]], dtype = 'object')\n",
    "#arr_E = np.array([[(121.7817*28.58 + 125.69*0.016)/(28.58+0.016),(244.6975*7.583+239.42*0.0046+251.630*0.072)/(7.583+0.0046+0.072),(344.2785*26.5+340.40*0.036+351.66*0.0093)/(26.5+0.036+0.0093),778.9040     ,(964.079*14.605+963.39*0.135+968*0.0037)/(14.605+0.135+0.0037),1408.006],[661.657]], dtype = 'object')\n",
    "arr_E = np.array([[(121.7817*28.58 + 125.69*0.016)/(28.58+0.016),(244.6975*7.583+239.42*0.0046+251.630*0.072)/(7.583+0.0046+0.072),(344.2785*26.5+340.40*0.036+351.66*0.0093)/(26.5+0.036+0.0093),778.9040     ,(964.079*14.605+963.39*0.135+968*0.0037)/(14.605+0.135+0.0037),1408.006],[661.657],[276.39,302.85,356.01,383.84],[1173.49,1333.22]], dtype = 'object')\n",
    "arr_xerr = np.array([[0.0003,0.0008,0.0012,0.0018,0.018,0.003],[0.003]], dtype = 'object') #very small: not taking into account for the weights\n",
    "#arr_yerr = np.array([[0.01*10**(-4),0.02*10**(-4),0.01*10**(-4),0.05*10**(-5),0.03*10**(-5),0.02*10**(-5)],[0.0210*10**(-5)]], dtype = 'object')\n",
    "arr_yerr = np.array([[0.062*10**(-4),0.073*10**(-4),0.037*10**(-4),0.088*10**(-5),0.134*10**(-5),0.023*10**(-5)],[0.199*10**(-5)],[0.105*10**(-4),0.091*10**(-4),0.067*10**(-4),0.056*10**(-4)],[0.057*10**(-5),0.043*10**(-5)]], dtype = 'object')\n",
    "\n",
    "# Diffent relative uncertainties, and plot labels/colors\n",
    "source_relers = [0.017,0.05,0.05,0.03]\n",
    "source_names = np.array([\"Eu152\", \"Cs137\", \"Ba133\", \"Co60\"])\n",
    "source_colors = np.array(['r', 'g', 'c','m','k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae086d",
   "metadata": {},
   "source": [
    "### Flatten the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_E = np.array([])\n",
    "vec_xerr = np.array([])\n",
    "vec_yerr = np.array([])\n",
    "vec_eff_stat = np.array([])\n",
    "lower_sys = np.zeros(N_points)\n",
    "upper_sys = np.zeros(N_points)\n",
    "mean_sys = np.zeros(N_points)\n",
    "\n",
    "for i in range(len(arr_E)):                                 # Assign the unchanged values and uncertainties\n",
    "    vec_E = np.append(vec_E, arr_E[i])\n",
    "    #vec_xerr = np.append(vec_xerr, arr_xerr[i])\n",
    "    vec_yerr = np.append(vec_yerr, arr_yerr[i])\n",
    "    vec_eff_stat = np.append(vec_eff_stat, arr_eff[i])\n",
    "    \n",
    "x_cont = np.linspace(10**-5, max(vec_E), N_points)\n",
    "model = Model(eff_fitfunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587519a",
   "metadata": {},
   "source": [
    "### Flatten the arrays (1 Source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9704e1ba",
   "metadata": {},
   "source": [
    "# Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = model.make_params(a0=-1, a1=0.01, a2=0, a3=0, a4=0)\n",
    "fitresult_stat = model.fit(vec_eff_stat, x=vec_E, params=pars, weights=1/vec_yerr)\n",
    "print(fitresult_stat.fit_report())\n",
    "\n",
    "fitvalue_stat = fitresult_stat.eval(x=x_cont)\n",
    "uncertainty_stat = fitresult_stat.eval_uncertainty(x=x_cont)\n",
    "print(max(uncertainty_stat))\n",
    "\n",
    "for index, value in enumerate(arr_eff):\n",
    "    plt.plot(arr_E[index], value, 'o', color=source_colors[index], label=source_names[index])\n",
    "    #plt.errorbar(arr_E[index], value, xerr=arr_xerr[index], yerr=arr_yerr[index], fmt='.', color=source_colors[index])\n",
    "    plt.errorbar(arr_E[index], value, yerr=arr_yerr[index], fmt='.', color=source_colors[index])\n",
    "\n",
    "plt.plot(x_cont, fitvalue_stat, 'b', linewidth=0.8)\n",
    "#plt.plot(x_cont, fitvalue_stat - uncertainty_stat, color='r', linewidth=0.8)\n",
    "#plt.plot(x_cont, fitvalue_stat + uncertainty_stat, color='r', linewidth=0.8)\n",
    "#plt.fill_between(x_cont, fitvalue_stat - uncertainty_stat, fitvalue_stat + uncertainty_stat, color='grey')\n",
    "plt.xlim([0, 1500])\n",
    "plt.ylabel(\"Efficiency (%)\")\n",
    "plt.legend(loc ='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfbcac",
   "metadata": {},
   "source": [
    "# Systematics analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b87aa1",
   "metadata": {},
   "source": [
    "### Pick activity from distribution and perform fit $N_{random}$ times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bdbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_values = np.ones([N_randoms, N_points])\n",
    "\n",
    "for i in range(N_randoms):\n",
    "    vec_eff = np.array([])\n",
    "    \n",
    "    for index_1, isotope in enumerate(arr_eff):\n",
    "        source_spread = np.random.normal(1, source_relers[index_1])\n",
    "        for index_2, value in enumerate(isotope):\n",
    "            vec_eff = np.append(vec_eff, value/source_spread)\n",
    "\n",
    "    pars = model.make_params(a0=1, a1=10**-2, a2=10**-2, a3=10**-2, a4 = 10**-2)\n",
    "    fitresult = model.fit(vec_eff, x=vec_E, params=pars, weights=1/vec_yerr)\n",
    "    fit_values[i] = fitresult.eval(x=x_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859590a3",
   "metadata": {},
   "source": [
    "### Find the [-1 $\\sigma$, +1 $\\sigma$] intervals for all x values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbe511",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = fit_values.T                                 # Get a list with all the values of the fit in x\n",
    "\n",
    "# sort list --> 15.87% and 84.13% are +-1sigma\n",
    "\n",
    "for i in range(N_points):                                   # Order the list to obtain +1 and -1 sigma values (15.87%; 84.13%)\n",
    "    distr_inpoint = np.sort(distribution[i])\n",
    "    lower_sys[i] = distr_inpoint[round(N_randoms * 0.1587)]\n",
    "    upper_sys[i] = distr_inpoint[round(N_randoms * 0.8413)]\n",
    "    mean_sys[i] = distr_inpoint[round(N_randoms*0.5)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c26c1",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "\n",
    "# Plot the fit and residues in a single figure\n",
    "fig = plt.figure(1)\n",
    "frame1 = fig.add_axes((.1,.2+.4,.8,.6 +.4))\n",
    "frame1.set_xticklabels([])\n",
    "\n",
    "# Plot the data points. Each isotope can get a different color\n",
    "for index, value in enumerate(arr_eff):\n",
    "    frame1.plot(arr_E[index], value, 'o', color=source_colors[index], label=source_names[index])\n",
    "    #frame1.errorbar(arr_E[index], value, xerr=arr_xerr[index], yerr=arr_yerr[index], fmt='.', color=source_colors[index])\n",
    "    frame1.errorbar(arr_E[index], value, yerr=arr_yerr[index], fmt='.', color=source_colors[index])\n",
    "\n",
    "    \n",
    "fit = fitresult_stat.eval(x=x_cont)\n",
    "\n",
    "frame1.plot(x_cont, mean_sys, color='b', linewidth=0.8)\n",
    "frame1.plot(x_cont, lower_sys, color='r', linewidth=0.8)\n",
    "frame1.plot(x_cont, upper_sys, color='r', linewidth=0.8)\n",
    "frame1.fill_between(x_cont, lower_sys, upper_sys, color='grey')\n",
    "frame1.set_xlim([0, 1500])\n",
    "frame1.tick_params(axis='y', which='major', labelsize=22)\n",
    "frame1.set_ylabel(\"Efficiency [%]\", size = 30)\n",
    "frame1.legend(loc ='best', fontsize = 30)\n",
    "frame1.grid()\n",
    "frame1.set_xlabel('Energy [keV]', size = 30)\n",
    "\n",
    "os.chdir(\"C:/Users/r0750853/Documents/aa figures\")\n",
    "plt.savefig('efficiency_overview.pdf')\n",
    "plt.show()\n",
    "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228809f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "\n",
    "# Plot the fit and residues in a single figure\n",
    "fig = plt.figure(1)\n",
    "frame1 = fig.add_axes((.1,.2+.4,.8,.6 +.4))\n",
    "frame1.set_xticklabels([])\n",
    "\n",
    "# Plot the data points. Each isotope can get a different color\n",
    "for index, value in enumerate(arr_eff):\n",
    "    frame1.plot(arr_E[index], value, 'o', color=source_colors[index], label=source_names[index])\n",
    "    #frame1.errorbar(arr_E[index], value, xerr=arr_xerr[index], yerr=arr_yerr[index], fmt='.', color=source_colors[index])\n",
    "    frame1.errorbar(arr_E[index], value, yerr=arr_yerr[index], fmt='.', color=source_colors[index])\n",
    "\n",
    "    \n",
    "fit = fitresult_stat.eval(x=x_cont)\n",
    "\n",
    "frame1.plot(x_cont, mean_sys, color='b', linewidth=0.8)\n",
    "frame1.plot(x_cont, lower_sys, color='r', linewidth=0.8)\n",
    "frame1.plot(x_cont, upper_sys, color='r', linewidth=0.8)\n",
    "frame1.fill_between(x_cont, lower_sys, upper_sys, color='grey')\n",
    "frame1.set_xlim([0, 1500])\n",
    "frame1.tick_params(axis='y', which='major', labelsize=22)\n",
    "frame1.set_ylabel(\"Efficiency (%)\", size = 30)\n",
    "frame1.legend(loc ='best', fontsize = 30)\n",
    "frame1.grid()\n",
    "\n",
    "\n",
    "frame2=fig.add_axes((.1,.2,.8,.4)) \n",
    "diff = vec_eff_stat - fitresult_stat.eval(x=vec_E)\n",
    "reldiff = 100 * diff/vec_eff_stat\n",
    "pos = 0\n",
    "\n",
    "for index, value in enumerate(arr_eff):\n",
    "    size = len(value)\n",
    "    frame2.plot(arr_E[index], diff[pos:pos+size], 'o', color=source_colors[index])\n",
    "    #frame2.errorbar(arr_E[index], diff[pos:pos+size], xerr=arr_xerr[index], yerr=arr_yerr[index], fmt='.', color=source_colors[index])\n",
    "    frame2.errorbar(arr_E[index], diff[pos:pos+size], yerr=arr_yerr[index], fmt='.', color=source_colors[index])\n",
    "    pos += size\n",
    "\n",
    "frame2.set_xlabel(\"Energy (keV)\", size = 30)\n",
    "frame2.set_ylabel(\"$\\Delta$(%)\", size = 30)\n",
    "frame2.set_xlim([0, 1500])\n",
    "frame2.tick_params(axis='both', which='major', labelsize=22)\n",
    "frame2.grid()\n",
    "\n",
    "os.chdir(\"C:/Users/r0750853/Documents/aa figures\")\n",
    "plt.savefig('efficiency_overview.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_point = 200\n",
    "\n",
    "print(eff_point(fitresult_stat, E_point))\n",
    "print(eff_errpoint(fitresult_stat, mean_sys, lower_sys, upper_sys, x_cont, E_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c86bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of the systematical error:\n",
    "energies = np.array([105.305,148.65,180.103,262.322,340.690,367.225])\n",
    "errup,errdown = eff_errpoint(fitresult_stat, mean_sys, lower_sys, upper_sys, x_cont, energies)[1:3]\n",
    "systerrorsup = errup/eff_errpoint(fitresult_stat, mean_sys, lower_sys, upper_sys, x_cont, energies)[0]\n",
    "systerrorsdown = errdown/eff_errpoint(fitresult_stat, mean_sys, lower_sys, upper_sys, x_cont, energies)[0]\n",
    "systematic_error = np.array([np.mean(systerrorsdown), np.mean(systerrorsup)])\n",
    "print('Relative systematical error (down) '+str(systematic_error[0]))\n",
    "print('Relative systematical error (up) '+str(systematic_error[1]))\n",
    "print(systerrorsdown)\n",
    "print(systerrorsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_cont, mean_sys, color='r', linewidth=0.8)\n",
    "for index, value in enumerate(arr_eff):\n",
    "    plt.plot(arr_E[index], value, 'o', color=source_colors[index], label=source_names[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd0ce1",
   "metadata": {},
   "source": [
    "# Functions to calculate the activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pybaselines import Baseline, utils\n",
    "import lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befeea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to transform from an energy to the corresponding channelnumber\n",
    "def energytochannel(energy):\n",
    "    return int((energy+0.99)/0.751)\n",
    "\n",
    "def linearmod(x, intercept, slope):\n",
    "    return intercept + x*slope\n",
    "\n",
    "def gausmod(x, amp, mu, sigma):\n",
    "    return (np.absolute(amp)/(np.sqrt(2*np.pi)*sigma)) * np.exp(-0.5 * ((x - mu)/sigma)**2)\n",
    "\n",
    "#function to calculate the activity that corresponds to a single peak in the spectrum\n",
    "def CalculatePeak(spectrum, livetime, inputDict, plot=False, print_check=False): \n",
    "    # spectrum corresponds to the number of counts per channelnumber, livetime to the corresponding livetime with which the spectrum was made\n",
    "    # inputDict contains the information specific to the peak that we want to know the corresponding activity of\n",
    "    # plot indicates whether the plots should be generated\n",
    "    \n",
    "    #extract the information from the dictionary\n",
    "    energy_peak = inputDict['energy_peak'] # central energy of the peak\n",
    "    intensity_peak = inputDict['intensity_peak'] # tabulated intensity of the peak\n",
    "    bg_start = inputDict['bg_range'][0] # start of the range in which we want to determine the background with the snip algorithm\n",
    "    bg_stop = inputDict['bg_range'][1] # end of the range in which we want to determine the background with the snip algorithm\n",
    "    fit_start = inputDict['fit_range'][0] # start of the range where the fit should start (defined with respect to the background range)\n",
    "    fit_stop = inputDict['fit_range'][1] # end of the range where the fit should start (defined with respect to the background range)\n",
    "    sigma_guess = inputDict['sigma_guess'] # first guess for the standarddeviation of the peak\n",
    "    number_of_peaks = inputDict['number_of_peaks'] # how many peaks should be fitted together\n",
    "    \n",
    "    chan = np.arange(0, 4096)\n",
    "    energies = chan*0.751 - 0.99\n",
    "    # Estimation for the background\n",
    "    x_bg = chan[energytochannel(bg_start):energytochannel(bg_stop)]\n",
    "    y_bg = spectrum[energytochannel(bg_start):energytochannel(bg_stop)]\n",
    "    baseline_fitter = Baseline(x_data=x_bg)\n",
    "    bg = baseline_fitter.snip(y_bg, max_half_window=20, decreasing=True)[0]\n",
    "    if plot==True:\n",
    "        plt.figure(figsize = (20,5))\n",
    "        plt.plot(chan, spectrum)\n",
    "        plt.xlim(0,800)\n",
    "        plt.plot(x_bg,bg)\n",
    "    # determine the fit range\n",
    "    x_tofit = x_bg[fit_start:fit_stop]\n",
    "    y_tofit = y_bg[fit_start:fit_stop] - bg[fit_start:fit_stop]\n",
    "    # make the models\n",
    "    if number_of_peaks == 1:\n",
    "        gmod = Model(gausmod) + Model(linearmod)\n",
    "    elif number_of_peaks == 2:\n",
    "        gmod = Model(gausmod,prefix = 'p1_') + Model(gausmod,prefix = 'p2_') + Model(linearmod)\n",
    "    elif number_of_peaks ==3:\n",
    "        gmod = Model(gausmod,prefix = 'p1_') + Model(gausmod,prefix = 'p2_') + Model(gausmod,prefix = 'p3_') + Model(linearmod)\n",
    "    else:\n",
    "        print(\"This program cannot fit more than 3 peaks at once\")\n",
    "    \n",
    "    amp_guess = np.max(y_tofit) * np.sqrt(2*np.pi) * sigma_guess\n",
    "    # initialize the parameters of the fit\n",
    "    if number_of_peaks == 1:\n",
    "        mu_guess = energytochannel(energy_peak)\n",
    "        params = gmod.make_params(amp = amp_guess, mu = mu_guess, sigma = sigma_guess, intercept = 0, slope = 0)\n",
    "    elif number_of_peaks == 2:\n",
    "        mu_guess = [energytochannel(energy_peak[0]),energytochannel(energy_peak[1])]\n",
    "        params = gmod.make_params(p1_amp = amp_guess, p1_mu = mu_guess[0], p1_sigma = sigma_guess, p2_amp = amp_guess, p2_mu = mu_guess[1], p2_sigma = sigma_guess, intercept = 0, slope = 0)\n",
    "    elif number_of_peaks == 3:\n",
    "        mu_guess = [energytochannel(energy_peak[0]),energytochannel(energy_peak[1]),energytochannel(energy_peak[2])]\n",
    "        params = gmod.make_params(p1_amp = amp_guess, p1_mu = mu_guess[0], p1_sigma = sigma_guess, p2_amp = amp_guess, p2_mu = mu_guess[1], p2_sigma = sigma_guess, p3_amp = amp_guess, p3_mu = mu_guess[2], p3_sigma = sigma_guess, intercept = 0, slope = 0)\n",
    "    \n",
    "    # determine the error for the weights that should be taken into account\n",
    "    stat_err = np.sqrt(y_bg[fit_start:fit_stop])\n",
    "    for index, value in enumerate(stat_err):\n",
    "        if value == 0:\n",
    "            stat_err[index] = 1\n",
    "            \n",
    "    result_fit = gmod.fit(y_tofit, params, x = x_tofit, weights = 1/stat_err)\n",
    "    if plot == 1:\n",
    "        plt.plot(x_bg, y_bg)\n",
    "        plt.plot(x_tofit, result_fit.eval(x=x_tofit) + bg[fit_start:fit_stop], 'r--')\n",
    "        plt.plot(np.linspace(100,200),-7.55430711610487*np.linspace(100,200) + 2346.89700374532)\n",
    "        if number_of_peaks == 1:\n",
    "            plt.plot(x_tofit,bg[fit_start:fit_stop] + gausmod(x_tofit, result_fit.params['amp'].value, result_fit.params['mu'].value, result_fit.params['sigma'].value) + linearmod(x_tofit, result_fit.params['intercept'].value,result_fit.params['slope'].value ),'k' )\n",
    "        else:        \n",
    "            plt.plot(x_tofit,bg[fit_start:fit_stop] + gausmod(x_tofit, result_fit.params['p1_amp'].value, result_fit.params['p1_mu'].value, result_fit.params['p1_sigma'].value) + linearmod(x_tofit, result_fit.params['intercept'].value,result_fit.params['slope'].value ),'k' )\n",
    "    # Calculate the activity\n",
    "    if print_check == True:\n",
    "        print('number of counts in the peak')\n",
    "        print(result_fit.params['amp'])\n",
    "    if number_of_peaks == 1:\n",
    "        if isinstance(result_fit.params['amp'].stderr, float):\n",
    "            if (result_fit.params['amp'].stderr/result_fit.params['amp'].value < 0.5): # if the fit is weak, the activity should be assigned to 0\n",
    "                Counts = uf(result_fit.params['amp'].value, result_fit.params['amp'].stderr)\n",
    "                eff = eff_errpoint(fitresult_stat, mean_sys, lower_sys, upper_sys, x_cont, energy_peak)[0]\n",
    "                activ_uf = np.abs(Counts / (intensity_peak*livetime*eff))\n",
    "                activ = activ_uf.n\n",
    "                stdev = activ_uf.s\n",
    "            else:\n",
    "                print('was not able to fit - 1')\n",
    "                activ = 0\n",
    "                stdev = 0\n",
    "        else:\n",
    "            print('was not able to fit - 2')\n",
    "            activ = 0\n",
    "            stdev = 0\n",
    "    else:\n",
    "        peaks_to_return = inputDict['155_peak_numbers']\n",
    "        activ  = []\n",
    "        stdev = []\n",
    "        for ii in peaks_to_return:\n",
    "            amp_step = 'p' + str(ii+1)+'_amp'\n",
    "            param_amp_step = result_fit.params[amp_step]\n",
    "            if isinstance(param_amp_step.stderr, float):\n",
    "                if (param_amp_step.stderr/param_amp_step.value < 0.5):\n",
    "                    Counts = uf(param_amp_step.value, param_amp_step.stderr)\n",
    "                    eff = eff_errpoint(fitresult_stat, mean_sys, lower_sys, upper_sys, x_cont, energy_peak[ii])[0]\n",
    "                    activ_uf = np.abs(Counts / (intensity_peak[ii]*livetime*eff))\n",
    "                    activ.append(activ_uf.n)\n",
    "                    stdev.append(activ_uf.s)\n",
    "                else:\n",
    "                    print('was not able to fit - 3')\n",
    "                    activ.append(0)\n",
    "                    stdev.append(0)\n",
    "            else:\n",
    "                print('was not able to fit - 4')\n",
    "                activ.append(0)\n",
    "                stdev.append(0)\n",
    "    return activ, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_peak1_156(spectrum, livetime, plot=False):\n",
    "    inputDict = {\n",
    "        \"energy_peak\" : 199.2132,\n",
    "        \"intensity_peak\" : 0.409,\n",
    "        \"bg_range\" : [0, 400],\n",
    "        \"fit_range\" : [260, 290],\n",
    "        \"sigma_guess\" : 7,\n",
    "        \"number_of_peaks\" : 1\n",
    "    }\n",
    "    activ, stdev = CalculatePeak(spectrum, livetime, inputDict, plot=plot)\n",
    "    return activ, stdev\n",
    "\n",
    "\n",
    "def Calculate_peak1_155(spectrum, livetime, plot=False):\n",
    "    inputDict = {\n",
    "        \"energy_peak\" : [90, 105.305],\n",
    "        \"intensity_peak\" : [1,0.25],\n",
    "        \"bg_range\" : [29,179],\n",
    "        \"fit_range\" : [70,130],\n",
    "        \"sigma_guess\" : 7,\n",
    "        \"number_of_peaks\" : 2,\n",
    "        \"155_peak_numbers\" : [1]\n",
    "    }\n",
    "    activ, stdev = CalculatePeak(spectrum, livetime, inputDict, plot=plot)\n",
    "    return activ, stdev\n",
    "\n",
    "def Calculate_peak1_155(spectrum, livetime, plot=False, print_check= False):\n",
    "    inputDict = {\n",
    "        \"energy_peak\" : 105.31,\n",
    "        \"intensity_peak\" : 0.25,\n",
    "        \"bg_range\" : [29,179],\n",
    "        \"fit_range\" : [85,130],\n",
    "        \"sigma_guess\" : 7,\n",
    "        \"number_of_peaks\" : 1,\n",
    "    }\n",
    "    activ, stdev = CalculatePeak(spectrum, livetime, inputDict, plot=plot,print_check=print_check)\n",
    "    return activ, stdev\n",
    "\n",
    "\n",
    "def Calculate_peak2_3_155(spectrum, livetime, plot=False):\n",
    "    inputDict = {\n",
    "        \"energy_peak\" : [148.65, 165.864, 180.103],\n",
    "        \"intensity_peak\" : [0.02648,0,0.0745],\n",
    "        \"bg_range\" : [40,500],\n",
    "        \"fit_range\" : [130,200],\n",
    "        \"sigma_guess\" : 7,\n",
    "        \"number_of_peaks\" : 3,\n",
    "        \"155_peak_numbers\" : [0,2]\n",
    "    }\n",
    "    activ, stdev = CalculatePeak(spectrum, livetime, inputDict, plot=plot)\n",
    "    return activ, stdev\n",
    "\n",
    "def Calculate_peak4_155(spectrum, livetime, plot=False):\n",
    "    inputDict = {\n",
    "        \"energy_peak\" : 262.322,\n",
    "        \"intensity_peak\" : 0.0529,\n",
    "        \"bg_range\" : [200,500],\n",
    "        \"fit_range\" : [60,110],\n",
    "        \"sigma_guess\" : 7,\n",
    "        \"number_of_peaks\" : 1\n",
    "    }\n",
    "    activ, stdev = CalculatePeak(spectrum, livetime, inputDict, plot=plot)\n",
    "    return activ, stdev\n",
    "\n",
    "def Calculate_peak5_6_155(spectrum, livetime, plot=False):\n",
    "    inputDict = {\n",
    "        \"energy_peak\" : [340.690, (367.225*0.0148+367.638*0.0078+367.929*0.0005+ 370.721*0.00228)/(0.0148 + 0.0078 + 0.0005 + 0.00228)],\n",
    "        \"intensity_peak\" : [0.01182,0.0148 + 0.0078 + 0.0005 + 0.00228],\n",
    "        \"bg_range\" : [300,550],\n",
    "        \"fit_range\" : [40,120],\n",
    "        \"sigma_guess\" : 4.5,\n",
    "        \"number_of_peaks\" : 2,\n",
    "        \"155_peak_numbers\" : [0,1]\n",
    "    }\n",
    "    activ, stdev = CalculatePeak(spectrum, livetime, inputDict, plot=plot)\n",
    "    return activ, stdev\n",
    "\n",
    "def Calculate_Ce(spectrum, livetime, plot=False):\n",
    "    inputDict = {\n",
    "        \"energy_peak\" : [148.65, 165.864, 180.103],\n",
    "        \"intensity_peak\" : [0,0.8,0],\n",
    "        \"bg_range\" : [40,500],\n",
    "        \"fit_range\" : [130,200],\n",
    "        \"sigma_guess\" : 7,\n",
    "        \"number_of_peaks\" : 3,\n",
    "        \"155_peak_numbers\" : [1]\n",
    "    }\n",
    "    activ, stdev = CalculatePeak(spectrum, livetime, inputDict, plot=plot)\n",
    "    return activ, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redchi(x,y,sigma_y,index_toskip=[]):\n",
    "    dof = len(y)-len(index_toskip)-1\n",
    "    chi = 0\n",
    "    for i in range(len(y)):\n",
    "        if i in index_toskip:\n",
    "            chi +=0\n",
    "        else:\n",
    "            chi += ((y[i]-x)/sigma_y[i])**2\n",
    "    red = chi/dof\n",
    "    if len(index_toskip)==5 or dof ==0:\n",
    "        red = 1\n",
    "    return red\n",
    "\n",
    "def new_err(old,redchi):\n",
    "    return np.sqrt(redchi)*old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1294871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the activity corresponding to Tb155\n",
    "def calculateactivities(summed_spectra, livetimes_summed_spectra,printen=False, plot=False):\n",
    "    # summed_spectra = array of all spectra as a function of the time\n",
    "    # livetimes_summed_spectra = livetimes for each of the spectra\n",
    "    # printen = indicates whether the results should be printed or not\n",
    "    # plot = indicates whether the graphs for each fit seperately are shown or not (DO NOT PUT THIS TO TRUE IF MANY SPECTRA NEED TO BE FITTED)\n",
    "    act_1_155 = []\n",
    "    err_1_155 = []\n",
    "    act_2_155 = []\n",
    "    act_3_155 = []\n",
    "    act_4_155 = []\n",
    "    err_2_155 = []\n",
    "    err_3_155 = []\n",
    "    err_4_155 = []\n",
    "    act_5_155 = []\n",
    "    act_6_155 = []\n",
    "    err_5_155 = []\n",
    "    err_6_155 = []\n",
    "    \n",
    "    #fit all of the peaks\n",
    "    for ll in range(len(summed_spectra)):       \n",
    "        peak1 = Calculate_peak1_155(summed_spectra[ll], livetimes_summed_spectra[ll], plot=plot)\n",
    "        act_1_155.append(peak1[0])\n",
    "        err_1_155.append(abs(peak1[1]))\n",
    "        peaks2 = Calculate_peak2_3_155(summed_spectra[ll], livetimes_summed_spectra[ll], plot=plot)\n",
    "        act_2_155.append(peaks2[0][0])\n",
    "        err_2_155.append(abs(peaks2[1][0]))\n",
    "        act_3_155.append(peaks2[0][1])\n",
    "        err_3_155.append(abs(peaks2[1][1])) \n",
    "        peak4 = Calculate_peak4_155(summed_spectra[ll], livetimes_summed_spectra[ll], plot=plot)\n",
    "        act_4_155.append(peak4[0])\n",
    "        err_4_155.append(abs(peak4[1]))\n",
    "        peaks5 = Calculate_peak5_6_155(summed_spectra[ll], livetimes_summed_spectra[ll], plot=plot)\n",
    "        act_5_155.append(peaks5[0][0])\n",
    "        err_5_155.append(abs(peaks5[1][0]))\n",
    "        act_6_155.append(peaks5[0][1])\n",
    "        err_6_155.append(abs(peaks5[1][1]))\n",
    "    act_1_155 = np.array(act_1_155)\n",
    "    act_2_155 = np.array(act_2_155)\n",
    "    act_3_155 = np.array(act_3_155)\n",
    "    act_4_155 = np.array(act_4_155)\n",
    "    act_5_155 = np.array(act_5_155)\n",
    "    act_6_155 = np.array(act_6_155)\n",
    "    err_1_155 = np.array(err_1_155)\n",
    "    err_2_155 = np.array(err_2_155)\n",
    "    err_3_155 = np.array(err_3_155)\n",
    "    err_4_155 = np.array(err_4_155)\n",
    "    err_5_155 = np.array(err_5_155)\n",
    "    err_6_155 = np.array(err_6_155)\n",
    "    # peak 4 is not purely Tb155, so we don't take it into account\n",
    "    allerrors155 = np.array([err_1_155, err_2_155 , err_3_155, err_5_155, err_6_155]) #statistical errors\n",
    "    #allerrors155 = np.array([err_1_155,err_2_155 , err_3_155, err_4_155, err_5_155, err_6_155]) #statistical errors\n",
    "    #allactivities155 = np.array([act_1_155,act_2_155,act_3_155,act_4_155,act_5_155,act_6_155])\n",
    "    allactivities155 = np.array([act_1_155, act_2_155, act_3_155, act_5_155, act_6_155])\n",
    "    \n",
    "       \n",
    "    total_errors = []\n",
    "    #add the systematic errors\n",
    "    for ii, energy in enumerate([105.305,148.65,180.103,340.690,376.6799]):\n",
    "        eff_info = eff_errpoint(fitresult_stat, mean_sys, lower_sys, upper_sys, x_cont, energy)\n",
    "        relative_error_eff = max(eff_info[1:3]/eff_info[0])\n",
    "        syst_err_act = np.array(allactivities155[ii])*relative_error_eff\n",
    "        total_errors.append(allerrors155[ii]+syst_err_act)\n",
    "    total_errors = (np.array(total_errors))\n",
    "    for ii in range(len(total_errors)):\n",
    "        for jj in range(len(total_errors[ii])):\n",
    "            if total_errors[ii,jj]==0:\n",
    "                total_errors[ii,jj]=1\n",
    "                \n",
    "    allactivities155 = [act_1_155, act_2_155, act_3_155, act_5_155, act_6_155]\n",
    "    meanactivities155 = np.zeros(len(act_1_155))\n",
    "    errorsom155 = np.zeros(len(act_1_155))\n",
    "    forerr155 = np.zeros(len(act_1_155))\n",
    "    # take the weighted sum\n",
    "    for ii in range(len(act_1_155)):\n",
    "        for jj in range(len(allactivities155)):\n",
    "            meanactivities155[ii]+=((allactivities155[jj])[ii])/(((total_errors[jj])[ii])**2)\n",
    "            errorsom155[ii]+=1/((total_errors[jj])[ii])**2\n",
    "            forerr155[ii]+=1/((total_errors[jj])[ii])**2\n",
    "    plt.figure(figsize=(10,10))\n",
    "    finalact155 = meanactivities155/errorsom155\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.title('Tb 155')\n",
    "    plt.xlabel('~Time')\n",
    "    plt.ylabel('Activity [MBq]')\n",
    "    plt.plot(np.array(finalact155)/10**6,'r.')\n",
    "    totalerror = np.sqrt(1/forerr155)/10**6 #in MBq\n",
    "    totalact = np.array(finalact155)/10**6 #in MBq\n",
    "    if printen==True:\n",
    "        print('155Tb, in MBq')\n",
    "        print(totalact)\n",
    "        print(totalerror)\n",
    "    \n",
    "    new_errors = []\n",
    "    for ii in range(len(totalact)):\n",
    "        red_chi_val = redchi(finalact155[ii],np.array(allactivities155)[:,ii],np.array(total_errors)[:,ii])\n",
    "        new_error = new_err(totalerror[ii],red_chi_val)\n",
    "        new_errors.append(new_error)\n",
    "    if printen==True:\n",
    "        print('New errors [MBq]')\n",
    "        print(np.array(new_errors))\n",
    "    \n",
    "    #plot the results\n",
    "    plt.errorbar(np.arange(len(finalact155)),finalact155/10**6 ,yerr=new_errors, markersize=1, fmt=\".\", color=\"black\",ecolor=\"black\")\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(act_1_155/10**6,'.',label='1')\n",
    "    plt.errorbar(np.arange(len(act_1_155)),act_1_155/10**6 ,yerr=err_1_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.plot(act_2_155/10**6,'.',label='2')\n",
    "    plt.errorbar(np.arange(len(act_2_155)),act_2_155/10**6 ,yerr=err_2_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.plot(act_3_155/10**6,'.',label='3')\n",
    "    plt.errorbar(np.arange(len(act_3_155)),act_3_155/10**6 ,yerr=err_3_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    #plt.plot(act_4_155/10**6,'.',label='4')\n",
    "    #plt.errorbar(np.arange(len(act_4_155)),act_3_155/10**6 ,yerr=err_4_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.plot(act_5_155/10**6,'.',label='5')\n",
    "    plt.errorbar(np.arange(len(act_5_155)),act_5_155/10**6 ,yerr=err_5_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.plot(act_6_155/10**6,'.',label='6')\n",
    "    plt.errorbar(np.arange(len(act_6_155)),act_6_155/10**6 ,yerr=err_6_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.ylim(-1,20)\n",
    "    \n",
    "    plt.legend()\n",
    "    return(totalact,np.array(new_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f14109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 and 6 seem to have a constant background, so the background will be subtracted for those\n",
    "def calculateactivities_backsubtr1_6(summed_spectra, livetimes_summed_spectra,printen=False, plot=False,backreg=[0]):\n",
    "    # summed_spectra = array of all spectra as a function of the time\n",
    "    # livetimes_summed_spectra = livetimes for each of the spectra\n",
    "    # printen = indicates whether the results should be printed or not\n",
    "    # plot = indicates whether the graphs for each fit seperately are shown or not (DO NOT PUT THIS TO TRUE IF MANY SPECTRA NEED TO BE FITTED)\n",
    "    act_1_155 = []\n",
    "    err_1_155 = []\n",
    "    act_2_155 = []\n",
    "    act_3_155 = []\n",
    "    act_4_155 = []\n",
    "    err_2_155 = []\n",
    "    err_3_155 = []\n",
    "    err_4_155 = []\n",
    "    act_5_155 = []\n",
    "    act_6_155 = []\n",
    "    err_5_155 = []\n",
    "    err_6_155 = []\n",
    "    \n",
    "    #fit all of the peaks\n",
    "    for ll in range(len(summed_spectra)):      \n",
    "        peak1 = Calculate_peak1_155(summed_spectra[ll], livetimes_summed_spectra[ll],plot=plot)\n",
    "        act_1_155.append(peak1[0])\n",
    "        err_1_155.append(abs(peak1[1]))\n",
    "        peaks2 = Calculate_peak2_3_155(summed_spectra[ll], livetimes_summed_spectra[ll],plot=plot)\n",
    "        act_2_155.append(peaks2[0][0])\n",
    "        err_2_155.append(abs(peaks2[1][0]))\n",
    "        act_3_155.append(peaks2[0][1])\n",
    "        err_3_155.append(abs(peaks2[1][1])) \n",
    "        peak4 = Calculate_peak4_155(summed_spectra[ll], livetimes_summed_spectra[ll],plot=plot)\n",
    "        act_4_155.append(peak4[0])\n",
    "        err_4_155.append(abs(peak4[1]))\n",
    "        peaks5 = Calculate_peak5_6_155(summed_spectra[ll], livetimes_summed_spectra[ll],plot=plot)\n",
    "        act_5_155.append(peaks5[0][0])\n",
    "        err_5_155.append(abs(peaks5[1][0]))\n",
    "        act_6_155.append(peaks5[0][1])\n",
    "        err_6_155.append(abs(peaks5[1][1]))\n",
    "    act_1_155 = np.array(act_1_155)\n",
    "    act_2_155 = np.array(act_2_155)\n",
    "    act_3_155 = np.array(act_3_155)\n",
    "    act_4_155 = np.array(act_4_155)\n",
    "    act_5_155 = np.array(act_5_155)\n",
    "    act_6_155 = np.array(act_6_155)\n",
    "    err_1_155 = np.array(err_1_155)\n",
    "    err_2_155 = np.array(err_2_155)\n",
    "    err_3_155 = np.array(err_3_155)\n",
    "    err_4_155 = np.array(err_4_155)\n",
    "    err_5_155 = np.array(err_5_155)\n",
    "    err_6_155 = np.array(err_6_155)\n",
    "    \n",
    "    # peak 4 is not purely Tb155\n",
    "    allerrors155 = np.array([err_1_155,err_2_155 , err_3_155, err_5_155, err_6_155])\n",
    "    #allerrors155 = np.array([err_1_155,err_2_155 , err_3_155, err_4_155, err_5_155, err_6_155]) #statistical errors\n",
    "    #allactivities155 = np.array([act_1_155,act_2_155,act_3_155,act_4_155,act_5_155,act_6_155])\n",
    "    allactivities155 = np.array([act_1_155,act_2_155,act_3_155,act_5_155,act_6_155])\n",
    "    \n",
    "       \n",
    "    total_errors = []\n",
    "    #add the systematic errors\n",
    "    for ii, energy in enumerate([105.305,148.65,180.103,340.690,376.6799]):#enumerate([105.305,148.65,180.103,262.322,340.690,376.6799]):\n",
    "        eff_info = eff_errpoint(fitresult_stat, mean_sys, lower_sys, upper_sys, x_cont, energy)\n",
    "        relative_error_eff = max(eff_info[1:3]/eff_info[0])\n",
    "        syst_err_act = np.array(allactivities155[ii])*relative_error_eff\n",
    "        total_errors.append(allerrors155[ii]+syst_err_act)\n",
    "    total_errors = (np.array(total_errors))\n",
    "    \n",
    "    for ii in range(len(total_errors)):\n",
    "        for jj in range(len(total_errors[ii])):\n",
    "            if total_errors[ii,jj]==0:\n",
    "                total_errors[ii,jj]=1\n",
    "    \n",
    "    #determination of the background\n",
    "    peak1_back = np.mean(act_1_155[backreg])\n",
    "    peak6_back = np.mean(act_6_155[backreg])\n",
    "    act_1_155 = act_1_155-peak1_back\n",
    "    act_6_155 = act_6_155-peak6_back\n",
    "    for ii in range(len(act_1_155)):\n",
    "        if act_1_155[ii]<0:\n",
    "            act_1_155[ii]=0\n",
    "        if act_6_155[ii]<0:\n",
    "            act_6_155[ii]=0\n",
    "    allactivities155 = [act_1_155, act_2_155, act_3_155, act_5_155, act_6_155]\n",
    "    #allactivities155 = [act_1_155, act_2_155, act_3_155, act_4_155, act_5_155, act_6_155]\n",
    "    meanactivities155 = np.zeros(len(act_1_155))\n",
    "    errorsom155 = np.zeros(len(act_1_155))\n",
    "    forerr155 = np.zeros(len(act_1_155))\n",
    "    # take the weighted sum\n",
    "    index_toskip = []\n",
    "    for ii in range(len(act_1_155)):\n",
    "        ind_add = []\n",
    "        for jj in range(len(allactivities155)):\n",
    "            if allerrors155[jj][ii]>0: # equal or smaller than zero is not taken into account\n",
    "                meanactivities155[ii]+=((allactivities155[jj])[ii])/(((total_errors[jj])[ii])**2)\n",
    "                errorsom155[ii]+=1/((total_errors[jj])[ii])**2\n",
    "                forerr155[ii]+=1/((total_errors[jj])[ii])**2\n",
    "            else:\n",
    "                ind_add.append(jj)\n",
    "        index_toskip.append(np.array(ind_add))\n",
    "    for jj in range(len(act_1_155)):\n",
    "        if meanactivities155[jj]==0:\n",
    "            print('bla')\n",
    "            errorsom155[jj]=1\n",
    "            forerr155[jj]=1\n",
    "            \n",
    "    plt.figure(figsize=(10,10))\n",
    "    finalact155 = meanactivities155/errorsom155\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.title('Tb 155')\n",
    "    plt.xlabel('~Time')\n",
    "    plt.ylabel('Activity [MBq]')\n",
    "    plt.plot(np.array(finalact155)/10**6,'r.')\n",
    "    totalerror = np.sqrt(1/forerr155)/10**6 #in MBq\n",
    "    for ii, actval in enumerate(finalact155):\n",
    "        if actval == 0:\n",
    "            totalerror[ii]=1\n",
    "    totalact = np.array(finalact155)/10**6 #in MBq\n",
    "    if printen==True:\n",
    "        print('155Tb, in MBq')\n",
    "        print(totalact)\n",
    "        print(totalerror)\n",
    "    \n",
    "    new_errors = []\n",
    "    for ii in range(len(totalact)):\n",
    "        red_chi_val = redchi(finalact155[ii],np.array(allactivities155)[:,ii],np.array(total_errors)[:,ii],index_toskip[ii])\n",
    "        new_error = new_err(totalerror[ii],red_chi_val)\n",
    "        new_errors.append(new_error)\n",
    "    if printen==True:\n",
    "        print('New errors [MBq]')\n",
    "        print(np.array(new_errors))\n",
    "    \n",
    "    #plot the results\n",
    "    plt.errorbar(np.arange(len(finalact155)),finalact155/10**6 ,yerr=new_errors, markersize=1, fmt=\".\", color=\"black\",ecolor=\"black\")\n",
    "    plt.ylim(-1,20)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.errorbar(np.arange(len(finalact155)),finalact155/10**6 ,yerr=totalerror, markersize=1, fmt=\".\", color=\"black\",ecolor=\"black\")\n",
    "    plt.ylim(-1,20)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(act_1_155/10**6,'.',label='1')\n",
    "    plt.errorbar(np.arange(len(act_1_155)),act_1_155/10**6 ,yerr=err_1_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.plot(act_2_155/10**6,'.',label='2')\n",
    "    plt.errorbar(np.arange(len(act_2_155)),act_2_155/10**6 ,yerr=err_2_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.plot(act_3_155/10**6,'.',label='3')\n",
    "    plt.errorbar(np.arange(len(act_3_155)),act_3_155/10**6 ,yerr=err_3_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    #plt.plot(act_4_155/10**6,'.',label='4')\n",
    "    #plt.errorbar(np.arange(len(act_4_155)),act_3_155/10**6 ,yerr=err_4_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.plot(act_5_155/10**6,'.',label='5')\n",
    "    plt.errorbar(np.arange(len(act_5_155)),act_5_155/10**6 ,yerr=err_5_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.plot(act_6_155/10**6,'.',label='6')\n",
    "    plt.errorbar(np.arange(len(act_6_155)),act_6_155/10**6 ,yerr=err_6_155/10**6, markersize=1, fmt=\".\", color=\"black\",alpha = 0.5, ecolor=\"black\")\n",
    "    plt.ylim(-1,20)\n",
    "    \n",
    "    plt.legend()\n",
    "    return(totalact,np.array(new_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50b428",
   "metadata": {},
   "source": [
    "# 4 July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df631d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_files = os.listdir(path='C:/Users/r0750853/Documents/analysis specta/Spectra-20230105T162014Z-001/Spectra')\n",
    "os.chdir('C:/Users/r0750853/Documents/analysis specta/Spectra-20230105T162014Z-001/Spectra')\n",
    "\n",
    "allspectra = []\n",
    "alltimes = []\n",
    "for ii, file in enumerate(ls_files):\n",
    "    if file[-4:len(ls_files)] == '.txt':\n",
    "        with open(file) as f:\n",
    "            lines = f.readlines()\n",
    "        toapp=[]\n",
    "        for jj in lines:\n",
    "            toapp.append(int(jj))\n",
    "        allspectra.append(toapp)\n",
    "        alltimes.append(file[7:26])\n",
    "livetime = np.zeros(int(len(ls_files)/2))\n",
    "ii=-1\n",
    "for file in (ls_files):\n",
    "    if file[-4:len(ls_files)] == '.spe':\n",
    "        ii+=1\n",
    "        with open(file) as f:\n",
    "            lines = f.readlines() \n",
    "        livetimestr = (lines[8][0:7])\n",
    "        if livetimestr == '$MEAS_T': #first file contains an extra line with the description\n",
    "            livetime[ii]= 120.123\n",
    "        else:\n",
    "            livetime[ii] = float(livetimestr)\n",
    "\n",
    "        \n",
    "x_channels = np.arange(0,4096)\n",
    "x_energy = 0.751*x_channels-0.99\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(x_energy, allspectra[110])\n",
    "plt.xlim(0,500)\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "startmeas = datetime.datetime.strptime(alltimes[1],'%d-%m-%Y_%H-%M-%S')\n",
    "tijden = []\n",
    "for ii in range(len(allspectra)):\n",
    "    datetime_obj = (datetime.datetime.strptime(alltimes[ii],'%d-%m-%Y_%H-%M-%S')-startmeas)\n",
    "    tijden.append((datetime_obj)/ pd.Timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd548a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = calculateactivities(allspectra[100:110], livetime[100:110],printen=True,plot=True)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d2291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = calculateactivities(allspectra, livetime,printen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(m[0],'.')\n",
    "plt.axvline(20)\n",
    "plt.axvline(190)\n",
    "print(len(m[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11068de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backregio = (np.arange(0,20,1))\n",
    "b = calculateactivities_backsubtr1_6(allspectra[0:25], livetime[0:25],printen=True, plot=False,backreg=backregio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7765af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "backregio = np.concatenate((np.arange(0,20,1),np.arange(190,258,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81752956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = calculateactivities_backsubtr1_6(allspectra, livetime,printen=True, plot=False,backreg=backregio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(b[0][1:202], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0][1:202]\n",
    "os.chdir('C:/Users/r0750853/Documents/Tb collections')\n",
    "np.savetxt('Activity_my_calculation.txt',b[0][1:202])\n",
    "np.savetxt('err_Activity_my_calculation.txt',b[1][1:202])\n",
    "np.savetxt('Activity_my_calculation_tijden.txt',tijden[1:202])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2f0d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = calculateactivities_not_1_and_6(allspectra, livetime,printen=True, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccbffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tijden,a[0],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903edf7d",
   "metadata": {},
   "source": [
    "# 15 July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289df277",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_files = os.listdir(path='C:/Users/r0750853/Documents/analysis specta/Spectra-20230109T070005Z-001/Spectra')\n",
    "os.chdir('C:/Users/r0750853/Documents/analysis specta/Spectra-20230109T070005Z-001/Spectra')\n",
    "\n",
    "allspectra = []\n",
    "alltimes = []\n",
    "for file in ls_files:\n",
    "    if file[-4:len(ls_files)] == '.txt':\n",
    "        with open(file) as f:\n",
    "            lines = f.readlines()\n",
    "        toapp=[]\n",
    "        for jj in lines:\n",
    "            toapp.append(int(jj))\n",
    "        allspectra.append(toapp)\n",
    "        alltimes.append(file[6:25])\n",
    "livetime = np.zeros(int(len(ls_files)/2))\n",
    "ii=-1\n",
    "for file in (ls_files):\n",
    "    if file[-4:len(ls_files)] == '.spe':\n",
    "        ii+=1\n",
    "        with open(file) as f:\n",
    "            lines = f.readlines() \n",
    "        livetimestr = (lines[8][0:7])\n",
    "        if livetimestr == '$MEAS_T': #first file contains an extra line with the description\n",
    "            livetime[ii]= 120.123\n",
    "        else:\n",
    "            livetime[ii] = float(livetimestr)\n",
    "\n",
    "        \n",
    "x_channels = np.arange(0,4096)\n",
    "x_energy = 0.751*x_channels-0.99\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(x_energy, allspectra[110])\n",
    "plt.xlim(0,500)\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "startmeas = datetime.datetime.strptime(alltimes[0],'%d-%m-%Y_%H-%M-%S')\n",
    "tijden = []\n",
    "for ii in range(len(allspectra)):\n",
    "    datetime_obj = (datetime.datetime.strptime(alltimes[ii],'%d-%m-%Y_%H-%M-%S')-startmeas)\n",
    "    tijden.append((datetime_obj)/ pd.Timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef350e04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = calculateactivities(allspectra, livetime,printen=True, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70fd75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a[0],'.')\n",
    "plt.axvline(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22965d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b2 = calculateactivities_backsubtr1_6(allspectra, livetime,printen=True, plot=False,backreg=np.arange(0,40,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72877cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(tijden[0:440])*60, b2[0][0:440],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08750816",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2[0][1:202]\n",
    "os.chdir('C:/Users/r0750853/Documents/Tb collections')\n",
    "np.savetxt('Activity_my_calculation_15jul.txt',b2[0][0:440])\n",
    "np.savetxt('err_Activity_my_calculation_15jul.txt',b2[1][0:440])\n",
    "np.savetxt('tijden_err_Activity_my_calculation_15jul.txt',tijden[0:440])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
